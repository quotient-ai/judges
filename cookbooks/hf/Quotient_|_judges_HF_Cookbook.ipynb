{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XJCjHC1Cig3c"
   },
   "source": [
    "# Using `judges` ‚öñÔ∏è to Build and Leverage LLM Evaluators  \n",
    "\n",
    "\n",
    "Evaluating the outputs of Large Language Models (LLMs) is often a challenging task, requiring nuanced criteria that are difficult to quantify and even harder to automate. For instance, how do we reliably assess if a model‚Äôs response is:  \n",
    "- factually accurate?  \n",
    "- concise yet comprehensive?  \n",
    "- free of hallucinations?  \n",
    "- aligned with ethical and domain-specific guidelines?  \n",
    "\n",
    "These questions demand a human-like understanding that traditional metrics like BLEU or ROUGE often fail to capture. Crafting rule-based systems for such evaluations is equally daunting due to the subjective and complex nature of these tasks.  \n",
    "\n",
    "‚úÖ Enter `judges`: an open-source library that simplifies and streamlines LLM evaluations with pre-built and customizable evaluators, inspired by research-backed methods like LLM-as-a-Judge. It‚Äôs designed for a wide range of use cases, from factual correctness to hallucination detection, and offers a low-friction interface for both quick setups and advanced customizations.  \n",
    "\n",
    "üí° The core idea is simple yet transformative: use LLMs themselves to evaluate other LLMs‚Äîefficiently, scalably, and with human-like reasoning.\n",
    "\n",
    "ü§ñ‚úì The prompts behind these LLM judges are backed by state-of-the-art research, including influential works such as _\"Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena\"_ ([Wang et al., 2023](https://arxiv.org/abs/2306.05685)) and _\"Replacing Judges with Juries: Evaluating LLM Generations with a Panel of Diverse Models\"_([Hu et al., 2024](https://arxiv.org/abs/2404.18796)).  \n",
    "\n",
    "In this cookbook, we‚Äôll use a subset of Google‚Äôs _Natural Questions_ dataset to demonstrate the use of `judges`. The task involves:  \n",
    "1. Starting with a pre-annotated dataset where responses are labeled as \"good\" or \"bad\" based on Wikipedia content.  \n",
    "2. Using AI search engines like Perplexity, EXA, and Gemini to generate responses similar to the \"good\" examples.  \n",
    "3. Applying `judges` to evaluate these responses for aspects like correctness and hallucination.   \n",
    "\n",
    "Through this process, you‚Äôll see how `judges` can simplify evaluation workflows while maintaining rigor and scalability. Let‚Äôs dive in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F-IXo8OXeS53",
    "outputId": "68fc4755-340a-4343-cd6b-9cc2997e12ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /Users/jamesliounis/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "if HF_API_KEY:\n",
    "    !huggingface-cli login --token $HF_API_KEY\n",
    "else:\n",
    "    print(\"Hugging Face API key not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nAURZgkw1qkb",
    "outputId": "dc9f19dd-831b-4616-be65-59dab64215b7"
   },
   "outputs": [],
   "source": [
    "# !python --version\n",
    "# !brew update\n",
    "# !brew upgrade python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2OOna81dUWj",
    "outputId": "6dac5b61-4176-412b-f210-ffacce193e74"
   },
   "outputs": [],
   "source": [
    "# !pip install judges datasets google-generativeai\n",
    "#!pip install exa_py\n",
    "# !pip uninstall openai --y\n",
    "# #!pip install openai==1.57.1 httpx==0.27.2\n",
    "# !pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "FCvMhvBOc5kD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from IPython.display import Markdown, HTML\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "hWW6wdPTdEW9",
    "outputId": "4f003a88-5248-450c-f42a-5a4527cec8d1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "086727000d3b4010acde2c92951fbdc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/3.60k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0dd9bebf314deb8c5efa2af840ae67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/17.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70cab7111f141c3a6a1d1cb3b441741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>input_text</th>\n",
       "      <th>completion</th>\n",
       "      <th>label</th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://en.wikipedia.org//w/index.php?title=De...</td>\n",
       "      <td>who did deion sanders go in the hall of fame as</td>\n",
       "      <td>['Cornerback']</td>\n",
       "      <td>bad</td>\n",
       "      <td>The answer is incorrect. The question is askin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://en.wikipedia.org//w/index.php?title=Un...</td>\n",
       "      <td>what is the title of the person who runs the h...</td>\n",
       "      <td>['Speaker of the House']</td>\n",
       "      <td>good</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://en.wikipedia.org//w/index.php?title=Th...</td>\n",
       "      <td>yo la tengo theres a riot going on release date</td>\n",
       "      <td>['March 16, 2018']</td>\n",
       "      <td>good</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://en.wikipedia.org//w/index.php?title=Th...</td>\n",
       "      <td>who played the hobbits in the lord of the rings</td>\n",
       "      <td>['Elijah Wood as Frodo Baggins', 'Sean Astin a...</td>\n",
       "      <td>good</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://en.wikipedia.org//w/index.php?title=Th...</td>\n",
       "      <td>where does the show the path take place</td>\n",
       "      <td>['Upstate New York']</td>\n",
       "      <td>good</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://en.wikipedia.org//w/index.php?title=De...   \n",
       "1  https://en.wikipedia.org//w/index.php?title=Un...   \n",
       "2  https://en.wikipedia.org//w/index.php?title=Th...   \n",
       "3  https://en.wikipedia.org//w/index.php?title=Th...   \n",
       "4  https://en.wikipedia.org//w/index.php?title=Th...   \n",
       "\n",
       "                                          input_text  \\\n",
       "0    who did deion sanders go in the hall of fame as   \n",
       "1  what is the title of the person who runs the h...   \n",
       "2    yo la tengo theres a riot going on release date   \n",
       "3    who played the hobbits in the lord of the rings   \n",
       "4            where does the show the path take place   \n",
       "\n",
       "                                          completion label  \\\n",
       "0                                     ['Cornerback']   bad   \n",
       "1                           ['Speaker of the House']  good   \n",
       "2                                 ['March 16, 2018']  good   \n",
       "3  ['Elijah Wood as Frodo Baggins', 'Sean Astin a...  good   \n",
       "4                               ['Upstate New York']  good   \n",
       "\n",
       "                                            feedback  \n",
       "0  The answer is incorrect. The question is askin...  \n",
       "1                                               None  \n",
       "2                                               None  \n",
       "3                                               None  \n",
       "4                                               None  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Replace \"quotientai/labeled-natural-qa-random-100\" with the actual dataset path\n",
    "dataset = load_dataset(\"quotientai/labeled-natural-qa-random-100\")\n",
    "\n",
    "data = dataset['train'].to_pandas()\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "80cFt3uhu6In"
   },
   "outputs": [],
   "source": [
    "# filter to have only the \"good\" data points\n",
    "\n",
    "data = data[data['label'] == 'good']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6NBl2u1Uxtv7"
   },
   "source": [
    "## Generating answers to our queries using AI Search engines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can either set the API keys from a `.env` file, such as what we are doing below, or from Google Colab secrets for which you may use the commented-out commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_dotenv()\n",
    "\n",
    "# print(f\"EXA_API_KEY: {EXA_API_KEY}\")\n",
    "# print(f\"GOOGLE_API_KEY: {GOOGLE_API_KEY}\")\n",
    "# print(f\"OPENAI_API_KEY: {OPENAI_API_KEY}\")\n",
    "# print(f\"PERPLEXITY_API_KEY: {PERPLEXITY_API_KEY}\")\n",
    "# print(f\"HF_API_KEY: {HF_API_KEY}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXA_API_KEY = os.getenv('EXA_API_KEY')\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "PERPLEXITY_API_KEY = os.getenv('PERPLEXITY_API_KEY')\n",
    "HF_API_KEY = os.getenv('HF_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLDRrvUUx8K5"
   },
   "source": [
    "### Gemini\n",
    "\n",
    "We use the Gemini API with the grounding option, following [official Google documentation](https://ai.google.dev/gemini-api/docs/grounding?lang=python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Vp_rUQ7vmjvt"
   },
   "outputs": [],
   "source": [
    "# from google.colab import userdata\n",
    "import google.generativeai as genai\n",
    "from IPython.display import Markdown, HTML\n",
    "\n",
    "# GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mci8jjd0mbMB"
   },
   "source": [
    "We first test out the Gemini client to see if everything works as planned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "1Q2vwaG9I0KB"
   },
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('models/gemini-1.5-pro-002')\n",
    "response = model.generate_content(contents=\"What is the land area of Spain?\",\n",
    "                                  tools='google_search_retrieval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "id": "nBGRGjW6lbgy",
    "outputId": "9865857c-dc81-4817-ee94-678fdc199f71"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Spain's land area covers approximately 500,000 square kilometers.  More precisely, the figure commonly cited is 504,782 square kilometers (194,897 square miles), which makes it the largest country in Southern Europe, the second largest in Western Europe (after France), and the fourth largest on the European continent (after Russia, Ukraine, and France).\n",
       "\n",
       "Including its island territories‚Äîthe Balearic Islands in the Mediterranean and the Canary Islands in the Atlantic‚Äîthe total area increases slightly to around 505,370 square kilometers.  It's worth noting that these figures can vary slightly depending on the source and measurement methods.  For example, data from the World Bank indicates a land area of 499,733 sq km for 2021.  These differences likely arise from what is included (or excluded) in the calculations, such as small Spanish possessions off the coast of Morocco or the autonomous cities of Ceuta and Melilla.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response.candidates[0].content.parts[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "id": "OHdh50cfyBRS",
    "outputId": "0f104df6-5f14-4049-a999-8ba01b761af0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(x)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.GenerativeModel('models/gemini-1.5-pro-002')\n",
    "\n",
    "\n",
    "def search_with_gemini(input_text):\n",
    "  response = model.generate_content(contents=input_text,\n",
    "                                    tools='google_search_retrieval')\n",
    "  return response\n",
    "\n",
    "\n",
    "\n",
    "parse_gemini_output = lambda x: x.candidates[0].content.parts[0].text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our functions ready, we run inference on our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [05:04<00:00,  4.54s/it]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "data['gemini_response'] = data['input_text'].progress_apply(search_with_gemini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['gemini_response_parsed'] = data['gemini_response'].apply(parse_gemini_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8uu2Icu1GBZ3"
   },
   "source": [
    "### Perplexity\n",
    "\n",
    "We quickstart the API using [this documentation](https://www.perplexity.ai/hub/blog/introducing-pplx-api)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XbPVbWDem99D"
   },
   "outputs": [],
   "source": [
    "# PERPLEXITY_API_KEY=userdata.get('PERPLEXITY_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "-GMBv3X_GCcJ"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "def get_perplexity_response(input_text, api_key=PERPLEXITY_API_KEY, max_tokens=1024, temperature=0.2, top_p=0.9):\n",
    "    \"\"\"\n",
    "    Sends an input text to the Perplexity API and retrieves a response.\n",
    "\n",
    "    Args:\n",
    "        input_text (str): The user query to send to the API.\n",
    "        api_key (str): The Perplexity API key for authorization.\n",
    "        max_tokens (int): Maximum number of tokens for the response.\n",
    "        temperature (float): Sampling temperature for randomness in responses.\n",
    "        top_p (float): Nucleus sampling parameter.\n",
    "\n",
    "    Returns:\n",
    "        dict: The JSON response from the API if successful.\n",
    "        str: Error message if the request fails.\n",
    "    \"\"\"\n",
    "    url = \"https://api.perplexity.ai/chat/completions\"\n",
    "\n",
    "    # Define the payload\n",
    "    payload = {\n",
    "        \"model\": \"llama-3.1-sonar-small-128k-online\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant. Be precise and concise.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": input_text\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": top_p,\n",
    "        \"search_domain_filter\": [\"perplexity.ai\"],\n",
    "        \"return_images\": False,\n",
    "        \"return_related_questions\": False,\n",
    "        \"search_recency_filter\": \"month\",\n",
    "        \"top_k\": 0,\n",
    "        \"stream\": False,\n",
    "        \"presence_penalty\": 0,\n",
    "        \"frequency_penalty\": 1\n",
    "    }\n",
    "\n",
    "    # Define the headers\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # Make the API request\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "    # Check and return the response\n",
    "    if response.status_code == 200:\n",
    "        return response.json()  # Return the JSON response\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}, {response.text}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "fjfivDbLndBW",
    "outputId": "ed6bee8b-1f1c-4a88-c478-bb49a5842369"
   },
   "outputs": [],
   "source": [
    "parse_perplexity_output = lambda response: response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [02:12<00:00,  1.98s/it]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "data['perplexity_response'] = data['input_text'].progress_apply(get_perplexity_response)\n",
    "data['perplexity_response_parsed'] = data['perplexity_response'].apply(parse_perplexity_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OiF_lU9asvqi"
   },
   "source": [
    "## Exa AI\n",
    "\n",
    "Exa doesn't have an integrated RAG API based on search results the same way that Perplexity and Gemini have. Instead, what they provide is a wrapper around OpenAI, for which we refer to [this documentation](https://docs.exa.ai/reference/openai). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "JVV4yKA_pyDe"
   },
   "outputs": [],
   "source": [
    "# !pip install exa_py\n",
    "\n",
    "from openai import OpenAI\n",
    "from exa_py import Exa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "bNU9kUs9zBhT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n",
      "The land area of Spain is approximately 505,370 square kilometers (195,124 square miles). This includes both the mainland and its island territories.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_exa_openai_response(openai_api_key=OPENAI_API_KEY, exa_key=EXA_API_KEY, model=\"gpt-4o-mini\", input_text=None):\n",
    "    \"\"\"\n",
    "    Generate a response using OpenAI GPT-4 via the Exa wrapper. Returns NaN if an error occurs.\n",
    "\n",
    "    Args:\n",
    "        openai_api_key (str): The API key for OpenAI.\n",
    "        exa_key (str): The API key for Exa.\n",
    "        model (str): The OpenAI model to use (e.g., \"gpt-4o-mini\").\n",
    "        input_text (str): The input text to send to the model.\n",
    "\n",
    "    Returns:\n",
    "        str or NaN: The content of the response message from the OpenAI model, or NaN if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize OpenAI and Exa clients\n",
    "        from openai import OpenAI\n",
    "        from exa_py import Exa\n",
    "        \n",
    "        openai = OpenAI(api_key=openai_api_key)\n",
    "        exa = Exa(exa_key)\n",
    "\n",
    "        # Wrap OpenAI with Exa\n",
    "        exa_openai = exa.wrap(openai)\n",
    "\n",
    "        # Generate a completion (disable tools)\n",
    "        completion = exa_openai.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": input_text}],\n",
    "            tools=None  # Ensure tools are not used\n",
    "        )\n",
    "\n",
    "        # Return the content of the first message in the completion\n",
    "        return completion.choices[0].message.content\n",
    "\n",
    "    except Exception as e:\n",
    "        # Log the error if needed (optional)\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        # Return NaN to indicate failure\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "# Testing the function\n",
    "response = get_exa_openai_response(\n",
    "    input_text=\"What is the land area of Spain?\"\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/67 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|‚ñé         | 2/67 [00:04<02:27,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 3/67 [00:08<03:03,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñå         | 4/67 [00:11<03:14,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|‚ñã         | 5/67 [00:15<03:28,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|‚ñâ         | 6/67 [00:19<03:34,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 7/67 [00:20<02:40,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|‚ñà‚ñè        | 8/67 [00:22<02:36,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|‚ñà‚ñé        | 9/67 [00:25<02:24,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|‚ñà‚ñç        | 10/67 [00:28<02:43,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|‚ñà‚ñã        | 11/67 [00:30<02:22,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|‚ñà‚ñä        | 12/67 [00:33<02:31,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|‚ñà‚ñâ        | 13/67 [00:37<02:41,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|‚ñà‚ñà        | 14/67 [00:42<03:15,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|‚ñà‚ñà‚ñè       | 15/67 [00:48<03:47,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|‚ñà‚ñà‚ñç       | 16/67 [00:53<03:51,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|‚ñà‚ñà‚ñå       | 17/67 [00:58<03:50,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|‚ñà‚ñà‚ñã       | 18/67 [01:00<03:02,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|‚ñà‚ñà‚ñä       | 19/67 [01:05<03:19,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñâ       | 20/67 [01:09<03:11,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|‚ñà‚ñà‚ñà‚ñè      | 21/67 [01:18<04:18,  5.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 22/67 [01:21<03:41,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred: Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_8GVRP40X0f03U67uTOZV6GJD\", 'type': 'invalid_request_error', 'param': 'messages', 'code': None}}\n",
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 23/67 [01:24<03:13,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 24/67 [01:28<02:58,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 25/67 [01:32<02:53,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|‚ñà‚ñà‚ñà‚ñâ      | 26/67 [01:34<02:23,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 27/67 [01:38<02:22,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28/67 [01:43<02:34,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 29/67 [01:46<02:23,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30/67 [01:49<02:15,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 31/67 [01:56<02:46,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32/67 [02:00<02:35,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 33/67 [02:02<02:01,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34/67 [02:06<02:00,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 35/67 [02:09<01:52,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36/67 [02:12<01:47,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 37/67 [02:17<01:58,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38/67 [02:20<01:46,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 39/67 [02:27<02:11,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40/67 [02:30<01:53,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 41/67 [02:31<01:24,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 42/67 [02:33<01:11,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 43/67 [02:37<01:14,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44/67 [02:40<01:11,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 45/67 [02:48<01:38,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46/67 [02:52<01:30,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 47/67 [02:55<01:18,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48/67 [02:58<01:12,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 49/67 [03:01<01:03,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50/67 [03:04<00:59,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 51/67 [03:05<00:43,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 52/67 [03:10<00:50,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 53/67 [03:13<00:46,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54/67 [03:17<00:42,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 55/67 [03:20<00:39,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56/67 [03:23<00:36,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 57/67 [03:26<00:32,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 58/67 [03:30<00:31,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 59/67 [03:33<00:26,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60/67 [03:37<00:23,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 61/67 [03:39<00:17,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 62/67 [03:44<00:18,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 63/67 [03:48<00:14,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64/67 [03:50<00:09,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 65/67 [03:54<00:07,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66/67 [04:00<00:04,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [04:05<00:00,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping OpenAI client with Exa functionality. <class 'function'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [04:07<00:00,  3.69s/it]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "data['exa_openai_response_parsed'] = data['input_text'].progress_apply(lambda x: get_exa_openai_response(input_text=x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['feedback', 'label'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../data/quotient_natural_qa_with_AI_search_completions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'when did 10 shilling note go out of circulation'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['input_text'][22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>input_text</th>\n",
       "      <th>completion</th>\n",
       "      <th>gemini_response</th>\n",
       "      <th>gemini_response_parsed</th>\n",
       "      <th>perplexity_response</th>\n",
       "      <th>perplexity_response_parsed</th>\n",
       "      <th>exa_openai_response_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://en.wikipedia.org//w/index.php?title=Un...</td>\n",
       "      <td>what is the title of the person who runs the h...</td>\n",
       "      <td>['Speaker of the House']</td>\n",
       "      <td>response:\\nGenerateContentResponse(\\n    done=...</td>\n",
       "      <td>The title of the person who runs the House of ...</td>\n",
       "      <td>{'id': '4acced38-a9bb-4f24-8e86-caadf25cab00',...</td>\n",
       "      <td>The title of the person who runs the House of ...</td>\n",
       "      <td>The title of the person who runs the House of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://en.wikipedia.org//w/index.php?title=Th...</td>\n",
       "      <td>yo la tengo theres a riot going on release date</td>\n",
       "      <td>['March 16, 2018']</td>\n",
       "      <td>response:\\nGenerateContentResponse(\\n    done=...</td>\n",
       "      <td>There are several albums and games with \"Riot\"...</td>\n",
       "      <td>{'id': '2fe35806-4b8d-45a2-9bd1-3b73f3f86faf',...</td>\n",
       "      <td>The release date for Yo La Tengo's album \"Ther...</td>\n",
       "      <td>Yo La Tengo's album **\"There's a Riot Going On...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://en.wikipedia.org//w/index.php?title=Th...</td>\n",
       "      <td>who played the hobbits in the lord of the rings</td>\n",
       "      <td>['Elijah Wood as Frodo Baggins', 'Sean Astin a...</td>\n",
       "      <td>response:\\nGenerateContentResponse(\\n    done=...</td>\n",
       "      <td>The four main hobbits in *The Lord of the Ring...</td>\n",
       "      <td>{'id': '943301b5-b371-431f-ae8a-ec9a6de4812b',...</td>\n",
       "      <td>In \"The Lord of the Rings: The Fellowship of t...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://en.wikipedia.org//w/index.php?title=Th...</td>\n",
       "      <td>where does the show the path take place</td>\n",
       "      <td>['Upstate New York']</td>\n",
       "      <td>response:\\nGenerateContentResponse(\\n    done=...</td>\n",
       "      <td>The show *The Path* primarily takes place in t...</td>\n",
       "      <td>{'id': '214c8f5e-1669-4bc4-ac5a-c9c4ac178cf2',...</td>\n",
       "      <td>The show \"The Path\" takes place in a rural set...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://en.wikipedia.org//w/index.php?title=Mi...</td>\n",
       "      <td>when did michigan last win a national champion...</td>\n",
       "      <td>['1989']</td>\n",
       "      <td>response:\\nGenerateContentResponse(\\n    done=...</td>\n",
       "      <td>Michigan last won a national championship in t...</td>\n",
       "      <td>{'id': '5774a4f3-a1a4-4e0b-8a96-7ad9d451e7c8',...</td>\n",
       "      <td>The 1948 Michigan Wolverines football team las...</td>\n",
       "      <td>The Michigan Wolverines last won a national ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://en.wikipedia.org//w/index.php?title=Un...   \n",
       "1  https://en.wikipedia.org//w/index.php?title=Th...   \n",
       "2  https://en.wikipedia.org//w/index.php?title=Th...   \n",
       "3  https://en.wikipedia.org//w/index.php?title=Th...   \n",
       "4  https://en.wikipedia.org//w/index.php?title=Mi...   \n",
       "\n",
       "                                          input_text  \\\n",
       "0  what is the title of the person who runs the h...   \n",
       "1    yo la tengo theres a riot going on release date   \n",
       "2    who played the hobbits in the lord of the rings   \n",
       "3            where does the show the path take place   \n",
       "4  when did michigan last win a national champion...   \n",
       "\n",
       "                                          completion  \\\n",
       "0                           ['Speaker of the House']   \n",
       "1                                 ['March 16, 2018']   \n",
       "2  ['Elijah Wood as Frodo Baggins', 'Sean Astin a...   \n",
       "3                               ['Upstate New York']   \n",
       "4                                           ['1989']   \n",
       "\n",
       "                                     gemini_response  \\\n",
       "0  response:\\nGenerateContentResponse(\\n    done=...   \n",
       "1  response:\\nGenerateContentResponse(\\n    done=...   \n",
       "2  response:\\nGenerateContentResponse(\\n    done=...   \n",
       "3  response:\\nGenerateContentResponse(\\n    done=...   \n",
       "4  response:\\nGenerateContentResponse(\\n    done=...   \n",
       "\n",
       "                              gemini_response_parsed  \\\n",
       "0  The title of the person who runs the House of ...   \n",
       "1  There are several albums and games with \"Riot\"...   \n",
       "2  The four main hobbits in *The Lord of the Ring...   \n",
       "3  The show *The Path* primarily takes place in t...   \n",
       "4  Michigan last won a national championship in t...   \n",
       "\n",
       "                                 perplexity_response  \\\n",
       "0  {'id': '4acced38-a9bb-4f24-8e86-caadf25cab00',...   \n",
       "1  {'id': '2fe35806-4b8d-45a2-9bd1-3b73f3f86faf',...   \n",
       "2  {'id': '943301b5-b371-431f-ae8a-ec9a6de4812b',...   \n",
       "3  {'id': '214c8f5e-1669-4bc4-ac5a-c9c4ac178cf2',...   \n",
       "4  {'id': '5774a4f3-a1a4-4e0b-8a96-7ad9d451e7c8',...   \n",
       "\n",
       "                          perplexity_response_parsed  \\\n",
       "0  The title of the person who runs the House of ...   \n",
       "1  The release date for Yo La Tengo's album \"Ther...   \n",
       "2  In \"The Lord of the Rings: The Fellowship of t...   \n",
       "3  The show \"The Path\" takes place in a rural set...   \n",
       "4  The 1948 Michigan Wolverines football team las...   \n",
       "\n",
       "                          exa_openai_response_parsed  \n",
       "0  The title of the person who runs the House of ...  \n",
       "1  Yo La Tengo's album **\"There's a Riot Going On...  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4  The Michigan Wolverines last won a national ch...  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/quotient_natural_qa_with_AI_search_completions.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "quotient",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
